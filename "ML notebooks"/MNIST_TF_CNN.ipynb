{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5wjahIZdRu6LHLVJ6noG8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elikaaghaei/Rahnema_college/blob/main/%22ML%20notebooks%22/MNIST_TF_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "YuAsYzvS2FvC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "sqExShM12n0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10  #total classes (0-9 digits).\n",
        "\n",
        "#Training Parameters\n",
        "learning_rate = 0.001\n",
        "trainig_steps = 200\n",
        "batch_size = 128\n",
        "display_step = 10\n",
        "\n",
        "#Network Parameters\n",
        "conv1_filters = 32 #number of filters for the first conv layer\n",
        "conv2_filters = 64 #number of filters for the second conv layer\n",
        "fc1_units = 1024 # umber of neurons for the fully connected layer"
      ],
      "metadata": {
        "id": "lCysXMEi2qx1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Dataset"
      ],
      "metadata": {
        "id": "Q5ZrpqnL4AN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test,y_test) = mnist.load_data()\n",
        "\n",
        "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)"
      ],
      "metadata": {
        "id": "I-a6eOyK3-0j"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train , x_test = x_train/255.0 , x_test /255.0"
      ],
      "metadata": {
        "id": "YdnDJWx84XGc"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))"
      ],
      "metadata": {
        "id": "EEMKo5rC4qT2"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
      ],
      "metadata": {
        "id": "Ye8Ui2cM42vN"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create TF model"
      ],
      "metadata": {
        "id": "dS0L7Y4w5uLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(Model):\n",
        "  #set layers\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "\n",
        "    self.conv1 = layers.Conv2D(32, kernel_size=5, activation=tf.nn.relu)\n",
        "    self.maxpool1 = layers.MaxPool2D(2, strides=2)\n",
        "    self.conv2 = layers.Conv2D(64 , kernel_size=3, activation = tf.nn.relu)\n",
        "    self.maxpool2 = layers.MaxPool2D(2, strides =2)\n",
        "    self.flatten = layers.Flatten()\n",
        "    self.fc1 = layers.Dense(1024)\n",
        "\n",
        "    #self.fc2 = layers.Dense(2048)\n",
        "    #self.dropout2 = layers.Dropout(rate =0.5)\n",
        "\n",
        "    self.dropout = layers.Dropout(rate =0.2)\n",
        "    self.out = layers.Dense(num_classes)\n",
        "\n",
        "  def call(self, x, is_training = False):\n",
        "    x = tf.reshape (x, [-1,28,28,1]) #?????\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    x = self.dropout(x, training = is_training)\n",
        "    #x = self.fc2(x)\n",
        "    #x = self.dropout2(x, training = is_training)\n",
        "    x = self.out(x)\n",
        "\n",
        "    if not is_training:\n",
        "      x = tf.nn.softmax(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "6lTPW4Lt5cE3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an object of that"
      ],
      "metadata": {
        "id": "YHB4ecsq89h3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_net = ConvNet()"
      ],
      "metadata": {
        "id": "dnT8U85m827S"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(x,y):\n",
        "  y = tf.cast(y, tf.int64)\n",
        "\n",
        "  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
        "  return tf.reduce_mean(loss)\n",
        "\n",
        "def accuracy(y_pred, y_true):\n",
        "  correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.cast(y_true, tf.int64))\n",
        "  return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
        "\n",
        "optimizer = tf.optimizers.Adam(learning_rate = learning_rate)"
      ],
      "metadata": {
        "id": "4X5IBXJDczr_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimization Process"
      ],
      "metadata": {
        "id": "YGoiUPDv9DF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def run_optimization(x,y):\n",
        "  with tf.GradientTape() as g:\n",
        "    pred = conv_net(x, is_training = True)\n",
        "    loss = cross_entropy_loss(pred,y)\n",
        "\n",
        "  trainable_variables = conv_net.trainable_variables\n",
        "\n",
        "  gradient = g.gradient(loss, trainable_variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradient, trainable_variables))"
      ],
      "metadata": {
        "id": "dDD4eE4f87_6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run training for a given data"
      ],
      "metadata": {
        "id": "ErKrhrkWd1ET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step, (batch_x, batch_y) in enumerate(train_data.take(trainig_steps),1):\n",
        "  run_optimization(batch_x, batch_y)\n",
        "\n",
        "  if step % display_step ==0:\n",
        "    pred = conv_net(batch_x)\n",
        "    loss = cross_entropy_loss(pred, batch_y)\n",
        "    acc = accuracy(pred, batch_y)\n",
        "    print(\"steps: %i, loss: %f, accuracy: %f\" %(step,loss,acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPR0-FP2dzFC",
        "outputId": "81cbed01-1580-4202-a3da-b07c28c32562"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "steps: 10, loss: 1.820090, accuracy: 0.820312\n",
            "steps: 20, loss: 1.624205, accuracy: 0.867188\n",
            "steps: 30, loss: 1.592002, accuracy: 0.906250\n",
            "steps: 40, loss: 1.558525, accuracy: 0.945312\n",
            "steps: 50, loss: 1.514492, accuracy: 0.976562\n",
            "steps: 60, loss: 1.548636, accuracy: 0.960938\n",
            "steps: 70, loss: 1.511889, accuracy: 0.960938\n",
            "steps: 80, loss: 1.530424, accuracy: 0.953125\n",
            "steps: 90, loss: 1.492814, accuracy: 1.000000\n",
            "steps: 100, loss: 1.511071, accuracy: 0.984375\n",
            "steps: 110, loss: 1.506704, accuracy: 0.984375\n",
            "steps: 120, loss: 1.491405, accuracy: 0.992188\n",
            "steps: 130, loss: 1.500378, accuracy: 0.968750\n",
            "steps: 140, loss: 1.500151, accuracy: 0.960938\n",
            "steps: 150, loss: 1.525207, accuracy: 0.953125\n",
            "steps: 160, loss: 1.492911, accuracy: 0.976562\n",
            "steps: 170, loss: 1.515489, accuracy: 0.960938\n",
            "steps: 180, loss: 1.488935, accuracy: 1.000000\n",
            "steps: 190, loss: 1.497555, accuracy: 0.968750\n",
            "steps: 200, loss: 1.481817, accuracy: 0.992188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = conv_net(x_test)\n",
        "\n",
        "print('Test Accuracy: %f' % accuracy(pred,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qObJLE7lgNB1",
        "outputId": "593db688-cab4-4eb1-bb06-336694e5bfa8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.980600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- we can use it via keras"
      ],
      "metadata": {
        "id": "BgkNf_UOhINz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can plot it"
      ],
      "metadata": {
        "id": "UsXaKQWLhFg8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9tb8Davhg9gz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}